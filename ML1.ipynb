{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp313-cp313-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp313-cp313-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp313-cp313-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp313-cp313-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/7.8 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/7.8 MB 1.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.8 MB 1.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.0/7.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 1.3/7.8 MB 1.2 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 1.6/7.8 MB 1.2 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 1.8/7.8 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 2.1/7.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 2.4/7.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 2.6/7.8 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 2.9/7.8 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.1/7.8 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 3.4/7.8 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 3.7/7.8 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 3.9/7.8 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.2/7.8 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.5/7.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 4.7/7.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.0/7.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 5.0/7.8 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.2/7.8 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.5/7.8 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 5.8/7.8 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.0/7.8 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.3/7.8 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.6/7.8 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.8/7.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.1/7.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.3/7.8 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.6/7.8 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp313-cp313-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.0/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp313-cp313-win_amd64.whl (55 kB)\n",
      "Downloading pillow-11.0.0-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.6 MB 1.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 0.8/2.6 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 1.3/2.6 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.6/2.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.8/2.6 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.1/2.6 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 2.4/2.6 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0 pyparsing-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.1.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.1 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 2.1/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 2.4/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 2.6/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 3.4/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 3.7/11.0 MB 1.2 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 3.9/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 4.2/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 5.0/11.0 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 5.2/11.0 MB 1.2 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 5.5/11.0 MB 1.2 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 5.8/11.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.0/11.0 MB 1.2 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 6.8/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 7.1/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 7.3/11.0 MB 1.2 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 7.6/11.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 8.4/11.0 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 8.7/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 8.9/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 9.2/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 10.0/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.2/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.5/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp313-cp313-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/44.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "    --------------------------------------- 0.8/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "    --------------------------------------- 1.0/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.3/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.6/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 1.8/44.5 MB 1.2 MB/s eta 0:00:37\n",
      "   - -------------------------------------- 2.1/44.5 MB 1.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 2.4/44.5 MB 1.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 2.6/44.5 MB 1.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 2.9/44.5 MB 1.2 MB/s eta 0:00:36\n",
      "   -- ------------------------------------- 3.1/44.5 MB 1.2 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 3.4/44.5 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.7/44.5 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 3.9/44.5 MB 1.2 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 4.2/44.5 MB 1.2 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 4.5/44.5 MB 1.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 4.7/44.5 MB 1.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 5.0/44.5 MB 1.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 5.2/44.5 MB 1.2 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 5.5/44.5 MB 1.2 MB/s eta 0:00:34\n",
      "   ----- ---------------------------------- 5.8/44.5 MB 1.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 6.0/44.5 MB 1.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 6.3/44.5 MB 1.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 6.6/44.5 MB 1.2 MB/s eta 0:00:33\n",
      "   ----- ---------------------------------- 6.6/44.5 MB 1.2 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 6.8/44.5 MB 1.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 7.1/44.5 MB 1.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 7.3/44.5 MB 1.2 MB/s eta 0:00:32\n",
      "   ------ --------------------------------- 7.6/44.5 MB 1.2 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 7.9/44.5 MB 1.2 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 8.1/44.5 MB 1.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 8.4/44.5 MB 1.2 MB/s eta 0:00:31\n",
      "   ------- -------------------------------- 8.7/44.5 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 8.9/44.5 MB 1.2 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 9.2/44.5 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.4/44.5 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 9.7/44.5 MB 1.2 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 10.0/44.5 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.2/44.5 MB 1.2 MB/s eta 0:00:30\n",
      "   --------- ------------------------------ 10.5/44.5 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 10.7/44.5 MB 1.2 MB/s eta 0:00:29\n",
      "   --------- ------------------------------ 11.0/44.5 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.3/44.5 MB 1.2 MB/s eta 0:00:29\n",
      "   ---------- ----------------------------- 11.5/44.5 MB 1.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 11.8/44.5 MB 1.2 MB/s eta 0:00:28\n",
      "   ---------- ----------------------------- 12.1/44.5 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 12.3/44.5 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 12.6/44.5 MB 1.2 MB/s eta 0:00:28\n",
      "   ----------- ---------------------------- 12.8/44.5 MB 1.2 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 13.1/44.5 MB 1.2 MB/s eta 0:00:27\n",
      "   ----------- ---------------------------- 13.1/44.5 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.4/44.5 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.6/44.5 MB 1.2 MB/s eta 0:00:27\n",
      "   ------------ --------------------------- 13.9/44.5 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 14.2/44.5 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------ --------------------------- 14.4/44.5 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 14.7/44.5 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 14.9/44.5 MB 1.2 MB/s eta 0:00:26\n",
      "   ------------- -------------------------- 15.2/44.5 MB 1.2 MB/s eta 0:00:25\n",
      "   ------------- -------------------------- 15.5/44.5 MB 1.2 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 15.7/44.5 MB 1.2 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 16.0/44.5 MB 1.2 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 16.3/44.5 MB 1.2 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 16.5/44.5 MB 1.2 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 16.8/44.5 MB 1.2 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 17.0/44.5 MB 1.2 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 17.3/44.5 MB 1.2 MB/s eta 0:00:24\n",
      "   --------------- ------------------------ 17.6/44.5 MB 1.2 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 17.8/44.5 MB 1.2 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 18.1/44.5 MB 1.2 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 18.4/44.5 MB 1.2 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 18.6/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 18.9/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 19.1/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 19.4/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 19.7/44.5 MB 1.2 MB/s eta 0:00:22\n",
      "   ----------------- ---------------------- 19.9/44.5 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 20.2/44.5 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 20.4/44.5 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 20.7/44.5 MB 1.2 MB/s eta 0:00:21\n",
      "   ------------------ --------------------- 21.0/44.5 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 21.2/44.5 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 21.5/44.5 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 21.8/44.5 MB 1.2 MB/s eta 0:00:20\n",
      "   ------------------- -------------------- 22.0/44.5 MB 1.2 MB/s eta 0:00:20\n",
      "   -------------------- ------------------- 22.3/44.5 MB 1.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 22.5/44.5 MB 1.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 22.8/44.5 MB 1.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 23.1/44.5 MB 1.2 MB/s eta 0:00:19\n",
      "   -------------------- ------------------- 23.3/44.5 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 23.6/44.5 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 23.9/44.5 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 24.1/44.5 MB 1.2 MB/s eta 0:00:18\n",
      "   --------------------- ------------------ 24.4/44.5 MB 1.2 MB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 24.6/44.5 MB 1.2 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 24.9/44.5 MB 1.2 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 1.2 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 1.2 MB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 25.4/44.5 MB 1.2 MB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 1.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 26.0/44.5 MB 1.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 26.2/44.5 MB 1.2 MB/s eta 0:00:16\n",
      "   ----------------------- ---------------- 26.5/44.5 MB 1.2 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 26.7/44.5 MB 1.2 MB/s eta 0:00:16\n",
      "   ------------------------ --------------- 27.0/44.5 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 27.3/44.5 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 27.5/44.5 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------------------ --------------- 27.8/44.5 MB 1.2 MB/s eta 0:00:15\n",
      "   ------------------------- -------------- 28.0/44.5 MB 1.2 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 28.3/44.5 MB 1.2 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 28.6/44.5 MB 1.2 MB/s eta 0:00:14\n",
      "   ------------------------- -------------- 28.8/44.5 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 29.1/44.5 MB 1.2 MB/s eta 0:00:14\n",
      "   -------------------------- ------------- 29.4/44.5 MB 1.2 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 29.6/44.5 MB 1.2 MB/s eta 0:00:13\n",
      "   -------------------------- ------------- 29.9/44.5 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 30.1/44.5 MB 1.2 MB/s eta 0:00:13\n",
      "   --------------------------- ------------ 30.4/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 30.7/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 30.9/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   --------------------------- ------------ 30.9/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 31.2/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 31.5/44.5 MB 1.2 MB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 31.7/44.5 MB 1.2 MB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 32.0/44.5 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 32.2/44.5 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 32.5/44.5 MB 1.2 MB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 32.8/44.5 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 33.0/44.5 MB 1.2 MB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 33.3/44.5 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 33.6/44.5 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 33.8/44.5 MB 1.2 MB/s eta 0:00:10\n",
      "   ------------------------------ --------- 34.1/44.5 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------ --------- 34.3/44.5 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 34.6/44.5 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 34.9/44.5 MB 1.2 MB/s eta 0:00:09\n",
      "   ------------------------------- -------- 35.1/44.5 MB 1.2 MB/s eta 0:00:08\n",
      "   ------------------------------- -------- 35.4/44.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 35.7/44.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 35.9/44.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 36.2/44.5 MB 1.2 MB/s eta 0:00:08\n",
      "   -------------------------------- ------- 36.4/44.5 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 36.7/44.5 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 37.0/44.5 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 37.2/44.5 MB 1.2 MB/s eta 0:00:07\n",
      "   --------------------------------- ------ 37.5/44.5 MB 1.2 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 37.5/44.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 38.0/44.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 38.5/44.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 38.8/44.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 39.1/44.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 39.3/44.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 39.3/44.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 39.6/44.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.1/44.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.4/44.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.6/44.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 40.9/44.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 41.2/44.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.4/44.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.7/44.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 41.9/44.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 42.2/44.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.5/44.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 42.7/44.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.0/44.5 MB 1.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 43.3/44.5 MB 1.2 MB/s eta 0:00:02\n",
      "   ---------------------------------------  43.5/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.8/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.0/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 1.2 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv('50_Startups.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
      "0  165349.20       136897.80        471784.10    New York  192261.83\n",
      "1  162597.70       151377.59        443898.53  California  191792.06\n",
      "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
      "3  144372.41       118671.85        383199.62    New York  182901.99\n",
      "4  142107.34        91391.77        366168.42     Florida  166187.94\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.sum of     R&D Spend  Administration  Marketing Spend  State  Profit\n",
       "0       False           False            False  False   False\n",
       "1       False           False            False  False   False\n",
       "2       False           False            False  False   False\n",
       "3       False           False            False  False   False\n",
       "4       False           False            False  False   False\n",
       "5       False           False            False  False   False\n",
       "6       False           False            False  False   False\n",
       "7       False           False            False  False   False\n",
       "8       False           False            False  False   False\n",
       "9       False           False            False  False   False\n",
       "10      False           False            False  False   False\n",
       "11      False           False            False  False   False\n",
       "12      False           False            False  False   False\n",
       "13      False           False            False  False   False\n",
       "14      False           False            False  False   False\n",
       "15      False           False            False  False   False\n",
       "16      False           False            False  False   False\n",
       "17      False           False            False  False   False\n",
       "18      False           False            False  False   False\n",
       "19      False           False            False  False   False\n",
       "20      False           False            False  False   False\n",
       "21      False           False            False  False   False\n",
       "22      False           False            False  False   False\n",
       "23      False           False            False  False   False\n",
       "24      False           False            False  False   False\n",
       "25      False           False            False  False   False\n",
       "26      False           False            False  False   False\n",
       "27      False           False            False  False   False\n",
       "28      False           False            False  False   False\n",
       "29      False           False            False  False   False\n",
       "30      False           False            False  False   False\n",
       "31      False           False            False  False   False\n",
       "32      False           False            False  False   False\n",
       "33      False           False            False  False   False\n",
       "34      False           False            False  False   False\n",
       "35      False           False            False  False   False\n",
       "36      False           False            False  False   False\n",
       "37      False           False            False  False   False\n",
       "38      False           False            False  False   False\n",
       "39      False           False            False  False   False\n",
       "40      False           False            False  False   False\n",
       "41      False           False            False  False   False\n",
       "42      False           False            False  False   False\n",
       "43      False           False            False  False   False\n",
       "44      False           False            False  False   False\n",
       "45      False           False            False  False   False\n",
       "46      False           False            False  False   False\n",
       "47      False           False            False  False   False\n",
       "48      False           False            False  False   False\n",
       "49      False           False            False  False   False>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#code to know null values\n",
    "dataset.isnull().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R&D Spend          0\n",
      "Administration     0\n",
      "Marketing Spend    0\n",
      "State              0\n",
      "Profit             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# find no. of null values in each column\n",
    "null_count=dataset.isnull().sum()\n",
    "print(null_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R&D Spend           73721.6156\n",
      "Administration     121344.6396\n",
      "Marketing Spend    211025.0978\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#mean of each column accept one column\n",
    "\n",
    "mean_column=dataset[['R&D Spend','Administration','Marketing Spend']].mean()\n",
    "print(mean_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     2\n",
      "1     0\n",
      "2     1\n",
      "3     2\n",
      "4     1\n",
      "5     2\n",
      "6     0\n",
      "7     1\n",
      "8     2\n",
      "9     0\n",
      "10    1\n",
      "11    0\n",
      "12    1\n",
      "13    0\n",
      "14    1\n",
      "15    2\n",
      "16    0\n",
      "17    2\n",
      "18    1\n",
      "19    2\n",
      "20    0\n",
      "21    2\n",
      "22    1\n",
      "23    1\n",
      "24    2\n",
      "25    0\n",
      "26    1\n",
      "27    2\n",
      "28    1\n",
      "29    2\n",
      "30    1\n",
      "31    2\n",
      "32    0\n",
      "33    1\n",
      "34    0\n",
      "35    2\n",
      "36    1\n",
      "37    0\n",
      "38    2\n",
      "39    0\n",
      "40    0\n",
      "41    1\n",
      "42    0\n",
      "43    2\n",
      "44    0\n",
      "45    2\n",
      "46    1\n",
      "47    0\n",
      "48    2\n",
      "49    0\n",
      "Name: State, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# convert encoder and decoder for state column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "dataset['State']=le.fit_transform(dataset['State'])\n",
    "print(dataset['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), slice(None, 3, None))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (slice(None, None, None), slice(None, 3, None))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# training data split\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m y\u001b[38;5;241m=\u001b[39mdataset[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3811\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[1;32m-> 3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), slice(None, 3, None))"
     ]
    }
   ],
   "source": [
    "# training data split\n",
    "x=dataset[:,:3].values\n",
    "y=dataset[:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giving training data set\n",
    "from sklearn.model_selection import train_test_split\n",
    "x=dataset[['R&D Spend','Administration','Marketing Spend']]\n",
    "y=dataset['Profit']\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend\n",
      "33   55493.95       103057.49        214634.81\n",
      "35   46014.02        85047.44        205517.64\n",
      "26   75328.87       144135.98        134050.07\n",
      "34   46426.07       157693.92        210797.67\n",
      "18   91749.16       114175.79        294919.57\n",
      "7   130298.13       145530.06        323876.68\n",
      "14  119943.24       156547.42        256512.92\n",
      "45    1000.23       124153.04          1903.93\n",
      "48     542.05        51743.15             0.00\n",
      "29   65605.48       153032.06        107138.38\n",
      "15  114523.61       122616.84        261776.23\n",
      "30   61994.48       115641.28         91131.24\n",
      "32   63408.86       129219.61         46085.25\n",
      "16   78013.11       121597.55        264346.06\n",
      "42   23640.93        96189.63        148001.11\n",
      "20   76253.86       113867.30        298664.47\n",
      "43   15505.73       127382.30         35534.17\n",
      "8   120542.52       148718.95        311613.29\n",
      "13   91992.39       135495.07        252664.93\n",
      "25   64664.71       139553.16        137962.62\n",
      "5   131876.90        99814.71        362861.36\n",
      "17   94657.16       145077.58        282574.31\n",
      "40   28754.33       118546.05        172795.67\n",
      "49       0.00       116983.80         45173.06\n",
      "1   162597.70       151377.59        443898.53\n",
      "12   93863.75       127320.38        249839.44\n",
      "37   44069.95        51283.14        197029.42\n",
      "24   77044.01        99281.34        140574.81\n",
      "6   134615.46       147198.87        127716.82\n",
      "23   67532.53       105751.03        304768.73\n",
      "36   28663.76       127056.21        201126.82\n",
      "21   78389.47       153773.43        299737.29\n",
      "19   86419.70       153514.11             0.00\n",
      "9   123334.88       108679.17        304981.62\n",
      "39   38558.51        82982.09        174999.30\n",
      "46    1315.46       115816.21        297114.46\n",
      "3   144372.41       118671.85        383199.62\n",
      "0   165349.20       136897.80        471784.10\n",
      "47       0.00       135426.92             0.00\n",
      "44   22177.74       154806.14         28334.72\n"
     ]
    }
   ],
   "source": [
    "print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33     96778.92\n",
      "35     96479.51\n",
      "26    105733.54\n",
      "34     96712.80\n",
      "18    124266.90\n",
      "7     155752.60\n",
      "14    132602.65\n",
      "45     64926.08\n",
      "48     35673.41\n",
      "29    101004.64\n",
      "15    129917.04\n",
      "30     99937.59\n",
      "32     97427.84\n",
      "16    126992.93\n",
      "42     71498.49\n",
      "20    118474.03\n",
      "43     69758.98\n",
      "8     152211.77\n",
      "13    134307.35\n",
      "25    107404.34\n",
      "5     156991.12\n",
      "17    125370.37\n",
      "40     78239.91\n",
      "49     14681.40\n",
      "1     191792.06\n",
      "12    141585.52\n",
      "37     89949.14\n",
      "24    108552.04\n",
      "6     156122.51\n",
      "23    108733.99\n",
      "36     90708.19\n",
      "21    111313.02\n",
      "19    122776.86\n",
      "9     149759.96\n",
      "39     81005.76\n",
      "46     49490.75\n",
      "3     182901.99\n",
      "0     192261.83\n",
      "47     42559.73\n",
      "44     65200.33\n",
      "Name: Profit, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    R&D Spend  Administration  Marketing Spend\n",
      "28   66051.52       182645.56        118148.20\n",
      "11  100671.96        91790.61        249744.55\n",
      "10  101913.08       110594.11        229160.95\n",
      "41   27892.92        84710.77        164470.71\n",
      "2   153441.51       101145.55        407934.54\n",
      "27   72107.60       127864.55        353183.81\n",
      "38   20229.59        65947.93        185265.10\n",
      "31   61136.38       152701.92         88218.23\n",
      "22   73994.56       122782.75        303319.26\n",
      "4   142107.34        91391.77        366168.42\n"
     ]
    }
   ],
   "source": [
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [40, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_squared_error\n\u001b[1;32m----> 2\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(mse)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:506\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m squared:\n\u001b[0;32m    502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m root_mean_squared_error(\n\u001b[0;32m    503\u001b[0m             y_true, y_pred, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, multioutput\u001b[38;5;241m=\u001b[39mmultioutput\n\u001b[0;32m    504\u001b[0m         )\n\u001b[1;32m--> 506\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    510\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:111\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    109\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, multioutput, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 111\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    113\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m check_array(y_pred, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    460\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [40, 10]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_train,y_test)\n",
    "print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
